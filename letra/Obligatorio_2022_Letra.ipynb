{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Obligatorio - Taller Agentes Inteligentes 2022\n",
    "\n",
    "Vamos a usar el juego pong de  (https://gym.openai.com/envs/Pong-v0/), en este caso, el juego está programado como un ambiente de OpenAI Gym, cumpliendo con las interfaces que hemos trabajado en el curso.\n",
    "\n",
    "El objetivo del juego consta de lograr pasar la pelota a traves de la linea del oponente, y que esta no pase a traves de la propia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./assets/images/pong.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si bien el juego podría considerarse de múltiples agentes, utilizaremos unicamente las heramientas del curso para solucionarlo, esto es, todo lo que no conforma a nuestros agentes será considerado ambiente y tratado como tal.\n",
    "\n",
    "El objetivo es resolver el juego utilizando Deep Q Learning y Double Deep Q Learning, comparando sus resultados y lograr que al menos uno de los algoritmos supere el puntaje 10 en el ambiente 'PongNoFrameskip-v4'.\n",
    "\n",
    "\n",
    "## Tareas:\n",
    "\n",
    "\n",
    "1. Completar el código faltante en este notebook (y archivos asociados).\n",
    "\n",
    "\n",
    "2. Entrenar un agente de Deep Q Learning (DQN) para cada ambiente tal que éste sea capaz de resolverlo.\n",
    "\n",
    "\n",
    "3. Entrenar un agente de Double Deep Q Learning (DDQN) para cada ambiente tal que éste sea capaz de resolverlo.\n",
    "\n",
    "\n",
    "4. Graficar las recompensas obtenidas para cada ambiente por cada agente (Ambos agentes resolviendo el ambiente 1 en una misma gráfica, idem para el ambiente 2). Escribir al menos 2 conclusiones de cada grafica. \n",
    "\n",
    "\n",
    "5. Grabar un video de cada agente resolviendo cada problema (pueden descargar el video desde colab y entregarlos dentro de un zip).\n",
    "\n",
    "\n",
    "Recuerden que pueden usar la GPU en google colab para agilizar el entrenamiento. \n",
    "***\n",
    "\n",
    "\n",
    "Fecha de entrega: **19/07** 21hs por gestión (gestion.ort.edu.uy). Pueden trabajar en grupos de hasta 3 estudiantes. \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YWf2qc2Hykps",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Instalación de librerías. Se fija la versión de gym, dado que para dicha versión las ROMS de los juegos ya estan includias y se evita su instalación separada lo que puede originar problemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r9wotKEgOaUW",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install --upgrade gym==0.19.0\n",
    "!pip install gym[all]\n",
    "!pip install \"gym[atari,accept-rom-license]\"\n",
    "!pip install matplotlib\n",
    "!pip install selenium\n",
    "!pip install webdriver-manager\n",
    "!pip install torch\n",
    "!pip install torchvision\n",
    "!pip install torchsummary\n",
    "!pip install matplotlib-colorbar\n",
    "!pip install tqdm\n",
    "!pip install opencv-python\n",
    "!pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "Imports y configuraciones de ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#Utils define rutinas auxiliares para procesamiento del ambiente\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.zeros(1).cuda()\n",
    "\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Running on {DEVICE}\")\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "print(\"Cuda Available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LTrzh2uLy-cB",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Creación del ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Running on {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bndnjRMRoglD",
    "outputId": "686c24cd-925d-4683-f2ed-ea88d1ac489f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ENV_NAME = \"PongNoFrameskip-v4\"\n",
    "\n",
    "test_env = gym.make(ENV_NAME)\n",
    "print(\"Actions #\",test_env.action_space.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qz1A4YeLrFgj",
    "outputId": "c10d9a3e-cf88-413b-d257-e868bfddafb9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(test_env.unwrapped.get_action_meanings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DA4X0mdirHLQ",
    "outputId": "1171cd7c-6731-4536-9d97-15a3384bec1c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(test_env.observation_space.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dentro de las funcionalidades de Utils, se encuentra la transformación de estados del ambiente para simplificar el procesamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./assets/images/frames.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un ejemplo en código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ENV_NAME = \"PongNoFrameskip-v4\"\n",
    "\n",
    "env = utils.make_env(ENV_NAME)\n",
    "observation = env.reset()\n",
    "for i in range(22):\n",
    "    if i > 20:\n",
    "        for j in range(4):\n",
    "            plt.imshow(observation[j], cmap='gray')\n",
    "            plt.show()\n",
    "\n",
    "    observation, _, _, _ = env.step(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Q Learning\n",
    "\n",
    "\n",
    "Recomendamos empezar implementando Deep Q Learning (paper presentado por DeepMind, pueden encontrar el mismo en arxiv: https://arxiv.org/pdf/1312.5602.pdf0).\n",
    "\n",
    "***\n",
    "\n",
    "En las celdas siguientes dejamos el código que deben implementar asi como una explicación del mismo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ajTGajUftSgY",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Memoria\n",
    "\n",
    "El algoritmo de Deep Q Learning presentado en el paper utiliza una memoria (llamada Replay Memory) para almacenar transiciones pasadas. Tuplas que contienen un estado base, la accion tomada, la recompensa obtenida, una bandera que indica si el siguiente estado es final o no; y el estado siguiente.\n",
    "\n",
    "Esta memoria es circular, es decir, tiene un límite maximo de elementos y una vez esté llena comienza a reemplazar los elementos más viejos.\n",
    "\n",
    "Vamos a necesitar crear una función **sample** que obtiene una mustra aleatoria de elementos de la memoria.  Esto puede ser una lista de Transiciones o listas separadas (pero alineadas) de los elementos que las componen.\n",
    "\n",
    "***\n",
    "\n",
    "Para implementar esta funcionalidad se debe modificar el archivo **replay_memory.py**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "scPtpbz4tTAh",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from replay_memory import ReplayMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7Ygv5Mjtb-F",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Modelo\n",
    "\n",
    "Vamos a usar un mismo modelo FeedForward para estos dos problemas (entrenado en cada problema particular). Recomendamos simplicidad en la creación del mismo, pero tienen total libertad al momento de implementarlo.\n",
    "\n",
    "***\n",
    "Para implementar esta funcionalidad se debe modificar el archivo **dqn_cnn_model.py**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bkNBvJB6ryp7",
    "outputId": "2120f7a5-1fbf-4613-a3a6-cd72aa330272",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from dqn_cnn_model import DQN_CNN_Model\n",
    "from utils import make_env\n",
    "\n",
    "test_env = make_env(ENV_NAME)\n",
    "\n",
    "test_net = DQN_CNN_Model(test_env.observation_space.shape, test_env.action_space.n).to(DEVICE)\n",
    "\n",
    "from torchsummary import summary\n",
    "summary(test_net, test_env.observation_space.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z9B7ZY9Htj_F",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Agente\n",
    "\n",
    "Vamos a definir una clase agente, encargado de interactuar con el ambiente y entrenar los modelos. Los métdos definidos deben funcionar para ambos problemas simplemente cambiando el modelo a utilizar para cada ambiente.\n",
    "\n",
    "Abajo dejamos un esqueleto del mismo y las funciones a completar. Recomendamos no alterar la estructura del mismo, pero pueden definir las funciones auxiliares que consideren necesarias.\n",
    "\n",
    "Una aclaracion particular es sobre los últimos tres parametros del agente, representan los valores de epsilon_inicial, epsilon_final y el tiempo (numero de steps) que tardamos en llegar del epsilon final al inicial (puede decrementarlo de forma lineal o exponencial en el número de steps).\n",
    "\n",
    "***\n",
    "\n",
    "Para implementar esta funcionalidad se debe modificar los archivos **abstract_agent.py**, **dqn_agent.py** y **double_dqn_agent.py**.\n",
    "\n",
    "Funciones a completar:\n",
    "\n",
    "\n",
    "1. init: que inicializa los parametros del agente.\n",
    "\n",
    "2. compute_epsilon: que computa el valor actual de epsilon en base al número de pasos actuales.\n",
    "\n",
    "3. select_action: Seleccionando acciones \"epsilongreedy-mente\" si estamos entranando y completamente greedy en otro caso.\n",
    "\n",
    "4. train: que entrena el agente por un número dado de episodios de largo determinado.\n",
    "\n",
    "5. record_test_episode: para grabar un episodio con el agente siempre seleccionando la mejor accion conocida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BOD-ENZRtyMt",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Entrenamiento\n",
    "\n",
    "Para entrenar van a necesitar definir:\n",
    "\n",
    "1. El ambiente (al entrenar **sin** hacer uso de la funcion `wrap_env`). \n",
    "2. Una instancia del modelo a utilizar para el problema (ej: `pong_model = DQNModel(espacio_obs, num_acciones)`.\n",
    "3. La función para procesar los estados (phi en el paper) que es necesaria para poder usar el modelo de Pytorch con las representaciones de gym.\n",
    "\n",
    "Una vez definido pueden llamar a la función train del agente para entrenarlo y problar las demás funciones.\n",
    "\n",
    "***\n",
    "\n",
    "Una de las cosas que recomendamos hacer para probar los algoritmos es entrenar el agente por una cantidad X de episodios, grabar un video para observar progreso, volver a entrenar el mismo agente y volver a grabar un video, todas las veces que considere necesario.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def process_state(obs):\n",
    "    # Transforme la observacion en un tensor de floats.\n",
    "    return ?\n",
    "\n",
    "#Hiperparámetros de entrenamiento del agente DQN\n",
    "TOTAL_STEPS =1000000\n",
    "EPISODES = 5\n",
    "STEPS = 10000\n",
    "\n",
    "EPSILON_INI = 1\n",
    "EPSILON_MIN = 0.02\n",
    "EPSILON_DECAY = 0.99998599985\n",
    "EPSILON_TIME = 1000\n",
    "EPISODE_BLOCK = 10\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "GAMMA = 0.99\n",
    "LEARNING_RATE = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101,
     "referenced_widgets": [
      "50f35bc059a84d5482f09ca12bb56f15",
      "8d5aafd9ee1d47ee93b9d04386010130",
      "27c0772379d54099b2a540681b14a3bb",
      "05822413100c4caf83a5786cb8b4c77a",
      "a5f125e5bf6c4806bf29fd89673f1c83",
      "7d75a94f71b24794b219650d8686eecb",
      "bdb4e9dd02b74d46b3db8abcf46be588",
      "7b37c2fd07904acb8415e50b6411d247",
      "ff07335e18384d0bba046f7142bd0b3b",
      "116f51e159084948940b43aabe0f0466",
      "01a671b47a6e48b48e41710f12c31ff1"
     ]
    },
    "id": "BsTl-pFqt10b",
    "outputId": "752b55e5-c9db-4f58-a182-4016687744fb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from dqn_agent import DQNAgent\n",
    "env = utils.make_env(ENV_NAME)\n",
    "\n",
    "# Cada vez que hacemos un experimento reseteamos la semilla para tener reproducibilidad\n",
    "env.seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "net = DQN_CNN_Model(env.observation_space.shape, env.action_space.n).to(DEVICE)\n",
    "\n",
    "\n",
    "#gym_env, model, obs_processing_func, memory_buffer_size, batch_size, learning_rate, gamma, epsilon_i, epsilon_f, epsilon_anneal_time\n",
    "agent = DQNAgent(env, net, process_state, BUFFER_SIZE, BATCH_SIZE, LEARNING_RATE, GAMMA, epsilon_i= EPSILON_INI, epsilon_f=EPSILON_MIN, epsilon_anneal_time=EPSILON_TIME, epsilon_decay = EPSILON_DECAY, episode_block = EPISODE_BLOCK)\n",
    "\n",
    "rewards = agent.train(EPISODES, STEPS, TOTAL_STEPS, writer_name = ENV_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tensorboard  --logdir=runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t5H88XXxuLVn",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Videos\n",
    "\n",
    "Para grabar los videos hacemos uso de la funcion `record_test_episode`  definida en nuestro agente asi como `wrap_env` para grabar los resultados.\n",
    "\n",
    "Dejamos un ejemplo de como hacerlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 477
    },
    "id": "pMZrPTlTuMCj",
    "outputId": "922c4fbc-875b-484d-f137-f30916373aa4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#initial environment\n",
    "env = make_env(ENV_NAME)\n",
    "wrapped_env = utils.wrap_env(env)\n",
    "agent.record_test_episode(wrapped_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "utils.show_video()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double Deep Q Learning\n",
    "\n",
    "Una variante del clásico algoritmo Q Learning, es Double Q Learning, este surge como solución al problema de sesgo de maximización. Esta variante fue rápidamente adaptada con tecnicás de optimización por decenso de gradientes (https://arxiv.org/pdf/1509.06461.pdf). Recomendamos leer el algoritmo del libro de Sutton y Barto para maximizar su entendimiento del mismo.\n",
    "\n",
    "***\n",
    "\n",
    "Vamos a utilizar el mismo modelo de red neuronal creado para el problema anterior y la misma implementación de memoria, dejamos un esqueleto de un agente de Double Deep Q learning para completar en el archivo **double_dqn_agent.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "env = make_env(ENV_NAME)\n",
    "from double_dqn_agent import DoubleDQNAgent\n",
    "# Cada vez que hacemos un experimento reseteamos la semilla para tener reproducibilidad\n",
    "env.seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "modelo_a = DQN_CNN_Model(env.observation_space.shape, env.action_space.n).to(DEVICE)\n",
    "modelo_b = DQN_CNN_Model(env.observation_space.shape, env.action_space.n).to(DEVICE)\n",
    "\n",
    "agent = DoubleDQNAgent(env, modelo_a, modelo_b, process_state, BUFFER_SIZE, BATCH_SIZE, LEARNING_RATE, GAMMA, epsilon_i= EPSILON_INI, epsilon_f=EPSILON_MIN, epsilon_anneal_time=EPSILON_TIME, epsilon_decay = EPSILON_DECAY, episode_block = EPISODE_BLOCK)\n",
    "\n",
    "rewards = agent.train(EPISODES, STEPS, TOTAL_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Hiperparámetros de entrenamiento del agente Doble DQN\n",
    "\n",
    "TOTAL_STEPS =1000000\n",
    "EPISODES = 5\n",
    "STEPS = 100000\n",
    "\n",
    "EPSILON_INI = 1\n",
    "EPSILON_MIN = 0.05\n",
    "EPSILON_DECAY = 0.99998599985\n",
    "EPSILON_TIME = 1000\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 4000\n",
    "\n",
    "GAMMA = 0.99\n",
    "LEARNING_RATE = 1e-4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#initial environment\n",
    "env = make_env(ENV_NAME)\n",
    "wrapped_env = utils.wrap_env(env)\n",
    "agent.record_test_episode(wrapped_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparaciones, Resultados, Comentarios...\n",
    "De aquí en adelante son libres de presentar como gusten los resultados comparativos de las técnicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Obligatorio_2022_Solucion.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01a671b47a6e48b48e41710f12c31ff1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "05822413100c4caf83a5786cb8b4c77a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_116f51e159084948940b43aabe0f0466",
      "placeholder": "​",
      "style": "IPY_MODEL_01a671b47a6e48b48e41710f12c31ff1",
      "value": " 50/50 [06:42&lt;00:00,  7.91s/ episodes]"
     }
    },
    "116f51e159084948940b43aabe0f0466": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "27c0772379d54099b2a540681b14a3bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7b37c2fd07904acb8415e50b6411d247",
      "max": 50,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ff07335e18384d0bba046f7142bd0b3b",
      "value": 50
     }
    },
    "50f35bc059a84d5482f09ca12bb56f15": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8d5aafd9ee1d47ee93b9d04386010130",
       "IPY_MODEL_27c0772379d54099b2a540681b14a3bb",
       "IPY_MODEL_05822413100c4caf83a5786cb8b4c77a"
      ],
      "layout": "IPY_MODEL_a5f125e5bf6c4806bf29fd89673f1c83"
     }
    },
    "7b37c2fd07904acb8415e50b6411d247": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d75a94f71b24794b219650d8686eecb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8d5aafd9ee1d47ee93b9d04386010130": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7d75a94f71b24794b219650d8686eecb",
      "placeholder": "​",
      "style": "IPY_MODEL_bdb4e9dd02b74d46b3db8abcf46be588",
      "value": "100%"
     }
    },
    "a5f125e5bf6c4806bf29fd89673f1c83": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bdb4e9dd02b74d46b3db8abcf46be588": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ff07335e18384d0bba046f7142bd0b3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}